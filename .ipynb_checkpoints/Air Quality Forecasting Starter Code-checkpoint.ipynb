{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTsEYdtov6tp"
   },
   "source": [
    "# Beijing Air Quality Forecasting Starter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nWkSHhqXrCqF"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gxW-6b_jrLAL"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# Ensure train.csv and test.csv are saved in your Google Drive in the same folder.\n",
    "# Replace the file paths below with the actual paths to your dataset.\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRse3uqRrft5"
   },
   "source": [
    "# Explore the training data\n",
    "\n",
    "In this sections explore your dataset with appropiate statistics and visualisations to understand your better. Ensure that you explain output of every code cell and what it entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "3R74CEBFrYok",
    "outputId": "0e593627-9c80-490c-826e-74e4df4a2249"
   },
   "outputs": [],
   "source": [
    "# Inspecting the first few rows of the dataset to understand its structure.\n",
    "print(\"Training Data Overview:\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-om6hH_RtG8Z",
    "outputId": "8fefc873-d80f-4b45-ead2-89bbfc8d4d62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'datetime', 'cbwd_NW',\n",
       "       'cbwd_SE', 'cbwd_cv', 'pm2.5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "35IGrMYRscQx"
   },
   "outputs": [],
   "source": [
    "# Ensure 'datetime' column is in datetime format\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "# Set the 'datetime' column as the index for better time-series handling\n",
    "train.set_index('datetime', inplace=True)\n",
    "# val.set_index('datetime', inplace=True)\n",
    "test.set_index('datetime', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABAqt0Jztd5s"
   },
   "source": [
    "# Handle missing values\n",
    "\n",
    "\n",
    "- Check the dataset for missing values and decide how to handle them.\n",
    "- In this example, missing values are filled with the mean. You can experiment with other strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "u2n29Ge1tami"
   },
   "outputs": [],
   "source": [
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKndkdRuty1C"
   },
   "source": [
    "# Separate features and target\n",
    "\n",
    "- Feel free to trop any non-essential columns like that you think might not contribute to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QETLRAo_tvQH"
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['pm2.5', 'No'], axis=1)\n",
    "y_train = train['pm2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NyP2mDjruG9R"
   },
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "# LSTM models require data in the shape (samples, timesteps, features).\n",
    "# Here, the data is reshaped to add a \"timesteps\" dimension.\n",
    "X_train = np.expand_dims(X_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# Build model\n",
    "\n",
    "Below is a simple LSTM model. Your task is to experiment with different parameters like, numbers of layers, units, activation functions, and optimizers, etc to get the best performing model. Experiment with other optimizers (e.g., SGD) or hyperparameters to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "mfx2LPHxq5fG",
    "outputId": "a5eab018-edc3-4ca5-f5f9-e896e2cbd0a1"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential([\n",
    "    LSTM(32, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=[lambda y, y_pred: tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uM0Xuq7XvdTZ",
    "outputId": "b6df9dee-acfd-416b-d50e-ab9b40201c73"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# You can adjust the number of epochs and batch size to improve performance.\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "NKxlO7SmxFpU",
    "outputId": "5bd92101-7840-44f2-eda6-2bf10a1680f3"
   },
   "outputs": [],
   "source": [
    "# Calculate training loss\n",
    "train_predictions = model.predict(X_train)\n",
    "train_loss = np.mean((y_train - train_predictions.flatten())**2)\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')  # Training loss during epochs\n",
    "plt.axhline(y=train_loss, color='blue', linestyle='--', label='Final rain Loss')  # Final training loss\n",
    "plt.title('Loss on Training Data')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Training Loss (MSE): {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nrw_e7OVwe6R",
    "outputId": "9a7966e6-fccf-409e-b3e4-c6ba968d610e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test data\n",
    "X_test = test.drop(['No'], axis=1)\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# Make predictions on the test set using trained model to predict \"pm2.5\" concentrations\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Ensure predictions do not contain NaN values\n",
    "predictions = np.nan_to_num(predictions)\n",
    "\n",
    "# Convert predictions to integers\n",
    "predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Prepare the submission file\n",
    "# Convert 'row ID' index to string and remove leading zeros for single-digit hours\n",
    "submission = pd.DataFrame({\n",
    "    'row ID': pd.to_datetime(test.index).strftime('%Y-%m-%d %-H:%M:%S'),  # Remove leading zeros for hours\n",
    "    'pm2.5': predictions.flatten()\n",
    "})\n",
    "\n",
    "# Sort the submission by 'row ID' to match the solution file exactly\n",
    "submission = submission.sort_values(by='row ID')\n",
    "\n",
    "# Save the file in CSV format for submission on Kaggle\n",
    "submission.to_csv('data/subm_fixed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
