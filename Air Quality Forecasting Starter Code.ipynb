{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTsEYdtov6tp"
   },
   "source": [
    "# Beijing Air Quality Forecasting Starter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWkSHhqXrCqF"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxW-6b_jrLAL"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# Ensure train.csv and test.csv are saved in your Google Drive in the same folder.\n",
    "# Replace the file paths below with the actual paths to your dataset.\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRse3uqRrft5"
   },
   "source": [
    "# Explore the training data\n",
    "\n",
    "In this sections explore your dataset with appropiate statistics and visualisations to understand your better. Ensure that you explain output of every code cell and what it entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "3R74CEBFrYok",
    "outputId": "0e593627-9c80-490c-826e-74e4df4a2249"
   },
   "outputs": [],
   "source": [
    "# Inspecting the first few rows of the dataset to understand its structure.\n",
    "print(\"Training Data Overview:\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-om6hH_RtG8Z",
    "outputId": "8fefc873-d80f-4b45-ead2-89bbfc8d4d62"
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35IGrMYRscQx"
   },
   "outputs": [],
   "source": [
    "# Ensure 'datetime' column is in datetime format\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "# Set the 'datetime' column as the index for better time-series handling\n",
    "train.set_index('datetime', inplace=True)\n",
    "# val.set_index('datetime', inplace=True)\n",
    "test.set_index('datetime', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABAqt0Jztd5s"
   },
   "source": [
    "# Handle missing values\n",
    "\n",
    "\n",
    "- Check the dataset for missing values and decide how to handle them.\n",
    "- In this example, missing values are filled with the mean. You can experiment with other strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2n29Ge1tami"
   },
   "outputs": [],
   "source": [
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "n_lags = 3\n",
    "\n",
    "for lag in range(1, n_lags + 1):\n",
    "    train[f'pm2.5_lag{lag}'] = train['pm2.5'].shift(lag)\n",
    "\n",
    "for lag in range(1, n_lags + 1):\n",
    "    test[f'pm2.5_lag{lag}'] = test['pm2.5'].shift(lag) if 'pm2.5' in test.columns else 0\n",
    "\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "train = train.dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKndkdRuty1C"
   },
   "source": [
    "# Separate features and target\n",
    "\n",
    "- Feel free to trop any non-essential columns like that you think might not contribute to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QETLRAo_tvQH"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_size = int(len(train) * 0.2)\n",
    "train_data = train.iloc[:-val_size]\n",
    "val_data = train.iloc[-val_size:]\n",
    "\n",
    "X_train = train_data.drop(['pm2.5', 'No'], axis=1)\n",
    "y_train = train_data['pm2.5']\n",
    "\n",
    "X_val = val_data.drop(['pm2.5', 'No'], axis=1)\n",
    "y_val = val_data['pm2.5']\n",
    "\n",
    "# Reshape for LSTM\n",
    "X_train = np.expand_dims(X_train, axis=1)\n",
    "X_val = np.expand_dims(X_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyP2mDjruG9R"
   },
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "# LSTM models require data in the shape (samples, timesteps, features).\n",
    "# Here, the data is reshaped to add a \"timesteps\" dimension.\n",
    "# X_train = np.expand_dims(X_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d488782wuR2W"
   },
   "source": [
    "# Build model\n",
    "\n",
    "Below is a simple LSTM model. Your task is to experiment with different parameters like, numbers of layers, units, activation functions, and optimizers, etc to get the best performing model. Experiment with other optimizers (e.g., SGD) or hyperparameters to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "mfx2LPHxq5fG",
    "outputId": "a5eab018-edc3-4ca5-f5f9-e896e2cbd0a1"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential([\n",
    "    LSTM(32, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=[lambda y, y_pred: tf.sqrt(tf.reduce_mean(tf.square(y - y_pred)))]  # RMSE metric\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uM0Xuq7XvdTZ",
    "outputId": "b6df9dee-acfd-416b-d50e-ab9b40201c73"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# You can adjust the number of epochs and batch size to improve performance.\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "NKxlO7SmxFpU",
    "outputId": "5bd92101-7840-44f2-eda6-2bf10a1680f3"
   },
   "outputs": [],
   "source": [
    "# Calculate training loss\n",
    "train_predictions = model.predict(X_train)\n",
    "train_loss = np.mean((y_train - train_predictions.flatten())**2)\n",
    "\n",
    "# Calculate validation loss (RMSE)\n",
    "val_predictions = model.predict(X_val)\n",
    "val_rmse = np.sqrt(np.mean((y_val - val_predictions.flatten())**2))\n",
    "\n",
    "# Persistence baseline: predict next value as previous value\n",
    "y_val_pred_persistence = y_val.shift(1).fillna(method='bfill')\n",
    "rmse_persistence = np.sqrt(np.mean((y_val - y_val_pred_persistence)**2))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Training Loss (MSE): {train_loss:.2f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.2f}\")\n",
    "print(f\"Persistence Baseline RMSE: {rmse_persistence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window_test(test_df, lookback):\n",
    "    X_test = []\n",
    "    # Use the same feature selection as training (drop 'No' and 'pm2.5' if present)\n",
    "    features_to_drop = ['No']\n",
    "    if 'pm2.5' in test_df.columns:\n",
    "        features_to_drop.append('pm2.5')\n",
    "    test_values = test_df.drop(features_to_drop, axis=1).values\n",
    "    \n",
    "    for i in range(lookback, len(test_df)):\n",
    "        X_test.append(test_values[i-lookback:i])\n",
    "    return np.array(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nrw_e7OVwe6R",
    "outputId": "9a7966e6-fccf-409e-b3e4-c6ba968d610e"
   },
   "outputs": [],
   "source": [
    "lookback = n_lags\n",
    "\n",
    "\n",
    "# Ensure test data has same features as training\n",
    "test_for_prediction = test.copy()\n",
    "if 'pm2.5' not in test_for_prediction.columns:\n",
    "    # If test doesn't have pm2.5, add dummy lag features\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        test_for_prediction[f'pm2.5_lag{lag}'] = 0\n",
    "\n",
    "# Build test sequences\n",
    "X_test_seq = create_sliding_window_test(test, lookback)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_seq)\n",
    "predictions = np.nan_to_num(predictions)\n",
    "predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Prepare submission (skip first 'lookback' rows)\n",
    "submission = pd.DataFrame({\n",
    "    'row ID': pd.to_datetime(test.index[lookback:]).strftime('%Y-%m-%d %-H:%M:%S'),\n",
    "    'pm2.5': predictions.flatten()\n",
    "})\n",
    "submission = submission.sort_values(by='row ID')\n",
    "submission.to_csv('data/subm_fixed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
